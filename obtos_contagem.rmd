---
title: "Trabalho 2 – Regressão para dados de contagem (RS)"
subtitle: "CE314 – Modelos Lineares Generalizados"
author: "Monica Ludmila, ......"
output:
  html_document:
    theme: journal
    number_sections: true
    code_folding: hide
---
___ 

Os dados referem-se aos municípios do Rio Grande do Sul, contendo informações de mortalidade e variáveis socioeconômicas.
A variável resposta é a contagem de pedestres traumatizados em um acidente de transporte. Disponíevel na guia Óbitos por causas externas, na seção Mortalidade – desde 1996 pela CID10

# Variáveis Pré-Selecionadas

<br><br>

| Variável | Descrição | Tipo |
| :--- | :--- | :---
| `obts` | Obtos por agressão |	Contagem (resposta). |
| `pop_est` | População estimada do município |	Contagem (offset – exposição)|
| `saneat` | Número de moradores com saneamento adequado |	Contagem |
| `pib_pc` | PIB per capita do município |	Contínua |
| `prop_bx_renda` | Proporção de pessoas com baixa renda |	Contínua |
| `renda_med_dom` | Renda média domiciliar | Contínua |
| `tx_analf` | Taxa de analfabetismo (%) |	Contínua |
| `municipio` | Nome do município |	Categórica (identificação) |

A variável resposta será o número de óbitos (obt_ocor), modelado como contagem. A variável pop_est será utilizada como offset (log da população) para ajustar o modelo pela exposição.

# Preparação dos Dados

## Leitura e Tratamento

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
libs <- c("ggplot2",
          "dplyr",
          "tidyverse",
          "magrittr",
          "stringr",
          "gridExtra",
          "corrplot",
          "hnp",
          "pscl",
          "MASS",
          "ggeffects")

for (lib in libs){
  
  if(!require(lib, character.only = TRUE)) install.packages(lib, repos = "https://cran-r.c3sl.ufpr.br/")
  
  library(lib, character.only = TRUE)
}

```
```{r leitura, message=FALSE, warning=FALSE}
# URL dos dados (Apenas o link puro, sem colchetes ou parenteses extras)
# url <- "https://gist.githubusercontent.com/jonhsp/40bdd288739a65a010e3c6385ddc37a1/raw/5226e1fb9f1786a4eff72a33c4dd4d95080b2547/DadosParaPobreSemExcel%2520(1).csv"
file <- "dados_contagem.csv"
df <- read_csv(file)
summary(df)
```

```{r tratamentos, message=FALSE, warning=FALSE}
df <- df %>%
  # Renomear para garantir consistência
  rename(
    municipio = Municipio,
    obts = 'ÓbtP/Ocor',
    saneat = Saneat,
    pib_pc = PibPerCapita,
    prop_bx_renda = PrpBxRnd,
    renda_med_dom = RndMdDom,
    tx_analf = TxAnalf,
    pop_est = PopEst
  ) %>%
  # Tratamento de caracteres e conversão numérica
  mutate(across(
    c(saneat, pib_pc, prop_bx_renda, renda_med_dom, tx_analf, pop_est),
    ~ as.numeric(str_replace_all(as.character(.), ",", "."))
  )) %>%
  drop_na() %>%
  filter(pop_est > 0) %>%
  # --- ENGENHARIA DE VARIÁVEIS ---
  # 1. Log da População (Offset obrigatório)
  mutate(log_pop = log(pop_est)) %>%
  # 2. Proporção de Saneamento (Para evitar colinearidade com a população absoluta)
  mutate(prop_saneat = (saneat / pop_est) * 100000) %>%
  # 3. Taxa de Mortalidade (Apenas para visualização gráfica)
  mutate(taxa_100k = (obts / pop_est) * 100000)

glimpse(df)
```
<br><br>

# Análise Exploratória
<br><br>

## Distribuição da Variável Resposta (Y)

Visualizamos a distribuição da contagem de óbitos (`obts`) para identificar a assimetria característica de dados de contagem e a presença de *outliers*.

```{r eda_distribuicao, message=FALSE, warning=FALSE, fig.align='center',fig.width=15, fig.height=6}


# 1. Histograma da Contagem Absoluta
p1 <- ggplot(df, aes(x = obts)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white", alpha = 0.9) +
  labs(title = "Distribuição de Óbitos", 
       subtitle = "Histograma da Variável Resposta",
       x = "Número de Óbitos", y = "Frequência") +
  theme_light()

# 2. Boxplot da Contagem
p2 <- ggplot(df, aes(y = obts)) +
  geom_boxplot(fill = "steelblue", outlier.colour = "red", outlier.shape = 1, alpha = 0.9) +
  labs(title = "Boxplot de Óbitos", 
       subtitle = "Identificação de Outliers",
       y = "Número de Óbitos", x = "") +
  theme_light() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

grid.arrange(p1, p2, ncol = 2)
```
<br><br>

## Correlação entre Variáveis (Multicolinearidade)

Verificamos a estrutura de correlação entre todas as variáveis numéricas disponíveis. O objetivo é identificar redundâncias que possam causar instabilidade no modelo (Multicolinearidade).

```{r eda_correlacao, message=FALSE, warning=FALSE, fig.align='center',fig.width=15, fig.height=6}
# Selecionar variáveis numéricas para correlação
df_cor <- df %>%
  dplyr::select(obts, pop_est, prop_saneat, pib_pc, prop_bx_renda, renda_med_dom, tx_analf) %>%
  cor(use = "complete.obs")

# Plotar Matriz
corrplot(df_cor, 
         method = "color", type = "upper", order = "hclust", 
         addCoef.col = "black", tl.col = "black", tl.srt = 45, 
         number.cex = 0.7, diag = FALSE, 
         title = "Matriz de Correlação", mar = c(0,0,1,0))

```
<br><br>

## Relação Individual: Preditores vs Taxa de Mortalidade

Visualizamos como cada variável explicativa se relaciona com a **taxa de mortalidade** (por 100k habitantes). Utilizamos a taxa no eixo Y para remover o efeito de tamanho populacional e identificar o risco real. As linhas vermelhas (suavização LOESS) ajudam a identificar tendências não-lineares.

```{r eda_preditores_all, message=FALSE, warning=FALSE, fig.align='center',fig.width=15, fig.height=6}
# Função auxiliar para plotagem uniforme
plot_dispersao <- function(var_x, label_x) {
  ggplot(df, aes(x = {{var_x}}, y = taxa_100k)) +
    geom_point(alpha = 0.4, color = "steelblue") +
    geom_smooth(method = "loess", color = "darkred", size = 0.8, se = FALSE) +
    labs(x = label_x, y = "Taxa (/100k)") +
    theme_light()
}

# Gerar plots
g1 <- plot_dispersao(prop_saneat, "Saneamento (%)")
g2 <- plot_dispersao(pib_pc, "PIB per Capita")
g3 <- plot_dispersao(prop_bx_renda, "Prop. Baixa Renda (%)")
g4 <- plot_dispersao(renda_med_dom, "Renda Média Domiciliar")
g5 <- plot_dispersao(tx_analf, "Tx. Analfabetismo (%)")

# Exibição conjunta
grid.arrange(g1, g2, g3, g4, g5, ncol = 2, 
             top = "Relação entre Preditores e Taxa de Mortalidade")

```
<br><br>
 
# Ajuste de Modelos

Para modelar a taxa de óbitos, iniciamos com o modelo de referência Poisson, utilizando o logaritmo da população (`log_pop`) como offset para controlar a exposição.

## Modelo 1: Poisson (Baseline)

```{r mod_poisson, message=FALSE, warning=FALSE}
# Ajuste do modelo Poisson com as covariáveis socioeconômicas e saneamento
ajuste_pois <- glm(obts ~ tx_analf + prop_saneat + prop_bx_renda + pib_pc, 
                   family = poisson, 
                   offset = log_pop, 
                   data = df)

summary(ajuste_pois)
```

## Modelo 2: Binomial Negativa
```{r mod_binomial_negativa, message=FALSE, warning=FALSE}

# Ajuste do modelo Binomial Negativo (trata superdispersão sem inflação de zeros)
ajuste_nb <- glm.nb(obts ~ tx_analf + prop_saneat + prop_bx_renda + pib_pc + offset(log_pop), 
                    data = df)

summary(ajuste_nb)

```
## Diagnóstico de Superdispersão

A validade do modelo Poisson depende da suposição de equidispersão (Média = Variância). Abaixo, verificamos se essa premissa é violada através do parâmetro de dispersão ($\phi$) e do gráfico de envelope simulado.
```{r diagnostico, message=FALSE, warning=FALSE, fig.align='center',fig.width=15, fig.height=6}
par(mfrow = c(1,2))

hnp(ajuste_nb, 
    pch = 20, 
    cex = 1.2, 
    main = "Envelope Simulado: Modelo BN",
    xlab = "Percentil Teórico", 
    ylab = "Resíduos Deviance")

hnp(ajuste_pois, 
    pch = 20, 
    cex = 1.2, 
    main = "Envelope Simulado: Modelo Poisson",
    xlab = "Percentil Teórico", 
    ylab = "Resíduos Deviance")
par(mfrow = c(1,1))
```

- **AIC:** O AIC caiu drasticamente de 1642.4 (no Poisson) para 1419.9 (neste Binomial Negativo). Uma redução de mais de 200 pontos confirma, sem sombra de dúvidas, que a distribuição Binomial Negativa é a correta para seus dados.
- **Gráfico Poisson:** Provavelmente exibe a maioria dos pontos (resíduos) fugindo drasticamente das faixas de confiança (envelope) em direção à parte superior direita.
- **Gráfico Binomial Negativa:** Exibe os pontos acomodados dentro (ou muito próximos) dos limites do envelope.
<br><br>

# Seleção de Variáveis (Stepwise)

```{r stepwise, message=FALSE, warning=FALSE}
# Aplica o algoritmo Stepwise (direção both) no modelo Binomial Negativo
# O algoritmo testará remover/adicionar variáveis para minimizar o AIC
modelo_final_nb <- stepAIC(ajuste_nb, direction = "both", trace = 1)

# Resumo do modelo vencedor selecionado pelo algoritmo
summary(modelo_final_nb)
```

# Avaliação do Processo Stepwise

A análise do stepAIC confirma que a maior parte das variáveis socioeconômicas não possui poder preditivo significativo para a taxa de óbitos, uma vez que o efeito da superdispersão foi corrigido.

O Modelo Final Binomial Negativo é:

$$\ln\left(\frac{\hat{\mu}}{\text{Pop}}\right) = -7.441 - 0.00001504 \cdot \text{prop\_saneat}$$

- Significância: prop_saneat é altamente significativa ($p \approx 0.0017$).

- Direção do Efeito: O coeficiente negativo ($-1.504e-05$) confirma o efeito protetor do saneamento: à medida que a proporção de saneamento adequado aumenta, a taxa de óbitos esperada diminui.

- Qualidade do Ajuste: O AIC final de 1413.11 representa uma melhoria substancial em relação ao modelo inicial de 4 variáveis (1417.88) e à Poisson original (1642.4).

<br><br>

# Visualização dos Resultados

```{r table_results, message=FALSE, warning=FALSE}
# Interpretação dos Resultados Finais

# O modelo final é: modelo_final_nb (apenas com prop_saneat)

# 1. Tabela de Razão de Taxas (RR)
# A função confint é usada para obter o Intervalo de Confiança.
rr_tabela <- data.frame(
  Coeficiente = coef(modelo_final_nb),
  RR = exp(coef(modelo_final_nb)),
  IC_2.5 = exp(confint(modelo_final_nb)[, 1]),
  IC_97.5 = exp(confint(modelo_final_nb)[, 2])
)

knitr::kable(rr_tabela, digits = 5, caption = "Razão de Taxas (Rate Ratios) - Modelo Final")
```
**Interpretação:** Um aumento de 1 ponto na proporção de saneamento adequado reduz a taxa de óbitos esperada em aproximadamente $1 - 0.99998 = 0.00002\%$. Embora o efeito por unidade seja minúsculo devido à escala da variável (/ 100k hab), o impacto é estatisticamente consistente.

```{r visualizacao, message=FALSE, warning=FALSE, fig.align='center',fig.width=15, fig.height=6}

# 2. Visualização dos Efeitos Marginais
plot(ggpredict(modelo_final_nb, terms = "prop_saneat")) +
  labs(
    title = "Efeito da Proporção de Saneamento na Taxa de Óbitos",
    y = "Óbitos Esperados (Contagem)",
    x = "Saneamento (por 100k hab.)"
  ) +
  theme_light()

```
<br><br>


##  Resíduos e Distância de Cook

```{r residuos, message=FALSE, warning=FALSE, fig.align='center',fig.width=15, fig.height=6}

# Configura a tela para 4 gráficos (2x2)
par(mfrow = c(2, 2))

# hnp
hnp(modelo_final_nb, resid.type = "deviance", how.many.out = TRUE, paint.out = TRUE,
    main = "Envelope Simulado", xlab = "Percentil Teórico", ylab = "Resíduos Deviance")

# Distância de Cook
plot(cooks.distance(modelo_final_nb), type = "h",
     main = "Distância de Cook",
     ylab = "Distância de Cook",
     ylim = c(0,0.6))
abline(h = 0.5, lty = 2, col = "red")

# Residuos deviance
plot(residuals(modelo_final_nb, type = "deviance"),
      main = "Resíduos Deviance",
      ylab = "Resíduos Deviance",
      ylim = c(-4, 4))
abline(h = c(-2, 2), lty = 2, col = "red")

# Residuos pearson
plot(residuals(modelo_final_nb, type = "pearson"),
      main = "Resíduos Pearson",
      ylab = "Resíduos Pearson",
      ylim = c(-4, 4))
abline(h = c(-2, 2), lty = 2, col = "red")

# Retorna a configuração da tela para o padrão (1 gráfico por vez)
par(mfrow = c(1, 1))
```
O diagnóstico realizado confirma a validade e estabilidade do seu modelo final de Regressão Binomial Negativa: a escolha da distribuição é correta, pois a totalidade dos pontos no Envelope Simulado permanece dentro das bandas de confiança; os resíduos de Pearson e Deviance situam-se em sua maioria no intervalo aceitável de $[-2, +2]$, indicando a ausência de outliers severos de ajuste; e, crucialmente, a Distância de Cook está bem abaixo do limite crítico de 0.5, demonstrando que nenhum município exerce influência indevida sobre as estimativas do coeficiente de Saneamento.